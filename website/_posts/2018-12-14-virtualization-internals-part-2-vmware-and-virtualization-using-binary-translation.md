---
layout: post
footer-space: true
current: blog
title:  "Virtualization Internals Part 2 - VMWare and Full Virtualization using Binary Translation"
page-title: "Virtualization Internals Part 2 - VMWare and Full Virtualization using Binary Translation"
categories: virtualization
excerpt_separator: <!--more-->
comments: true
---
In the previous chapter, we have introduced some basic concepts about hypervisors and briefly touched upon the different techniques to virtualize x86: full virtualization using binary translation, paravirtualization and hardware virtualization. Today, we will dig deeper into full virtualization and particularly how early versions of VMWare Workstation successfully bringed virtualization back to x86 regardless the lack of virtualization support back in time and the deep complexity of the architecture.
<!--more-->
- [Virtualization Internals Part 1 - Intro to Virtualization](https://saferwall.com/blog/virtualization-internals-part-1-intro-to-virtualization)
- Virtualization Internals Part 2 - VMWare and Full Virtualization using Binary Translation (current)
- Virtualization Internals Part 3 - Xen and Paravirtualization
Before we proceed further, I would like to stress that what we will be discussing in this chapter was specifically designed to virtualize x86 architecture before the introduction of 64-bit extensions or hardware support for virtualization [(VT-x and AMD-v)](https://en.wikipedia.org/wiki/X86_virtualization#Intel_virtualization_(VT-x)) [2006]. VMware’s currently shipping VMMs are noticeably different from its original design. Nevertheless, the knowledge you will learn will extend your understading on virtualization and low level concepts.
## Some few words about VMWare
VMWare started with two hypervisors solutions: `Workstation` and `ESX`. The first release of VMWare Workstation goes back to 1999 [(release build history)](http://www.virten.net/vmware/workstation-release-and-build-number-history/). ESX comes somewhere in 2001 [(release build history)](http://www.virten.net/vmware/esxi-release-build-number-history/). Workstation is considered as a hosted (type2) architecture while ESX runs over bare-metal (type1) architecture. In this post, we will focus on `VMWare Workstation`.
<p align="center"> 
    <img src="https://i.imgur.com/j6noR4X.png" width="600px" height="auto" alt="Ubuntu host running Windows 10 with VMWare Workstation">
</p>
If you would like to take a look at the VMM, download the setup from [here](http://linux2.mathematik.tu-darmstadt.de/pub/linux/mirrors/misc/old/vmware/VMware-1.0.1-372.exe), install it in a Windows XP VM, once installed, locate vmware.exe in `ProgramFiles` directory, open it with a PE ressource editor like [CFF Explorer](http://www.ntcore.com/exsuite.php) and dump the binaries, the VMM is a `ELF` file.
## VMWare Workstation hosted architecture
As we have seen in the first article, a hosted architecture allows virtualization to be inserted into an existing OS. VMWare is packaged as a normal application which contains a set of drivers and execuatble/dll files. Running as a normal application had numerous benefits. In the first hand, VMWare relied on the host graphical user interface so that the content of each VM’s screen would naturally appear within a distinct window which results on a good user exprience. From the other hand, each VM instance run as a process (`vmware-vmx.exe`) on the host OS which could be independently started, monitored or terminated. This process will be labeled `VMX` in this chapter.
<p align="center"> 
    <img src="https://i.imgur.com/76yl8fG.png" height="auto" alt="Two running VMs under vmwaree-vmx.exe">
</p>
In addition to that, running on top of a host OS helps on I/O device emulation. As the host OS could talk to every I/O device using its own device drivers, VMWare backed its emulated device with standard syscalls to the host OS. For example, it would read or write a file in the host file system to emulate a virtual disk device, or draw in a window of the host’s desktop to emulate a video card. As long as the host OS had the appropriate drivers, VMware could run virtual machines on top of it.
However, a normal application does not have the necessary APIs or facilities for a VMM to multiplex the CPU and memory resources. As a result, VMware only appears to run on top of an existing OS when in fact its VMM can operate at system level, in full control of the hardware. In fact, the host OS rightfully assumes that it is in control of the hardware resources at all the times. However, the VMM actually does take control of the hardware for some bounded amount of time during which the host OS is temporarily removed from virtual and linear memory.
<p align="center"> 
    <img src="https://i.imgur.com/6W2nHCr.png" width="700px" height="auto" alt="VMWare Hosted Architecture">
</p>
As you can from the illustration above, at any point in time, each CPU could be either in the:
- host OS context in which the OS is fully in control, or;
- VMM context where the VMM is fully in control.
The context switch between the VMM and the host OS was dubbed the `world switch`. Each context have its own address spaces, interrupt descriptor tables, stacks, execution contexts. The `VMM driver` which is resident in the host implemented a set of operations, including locking physical memory pages, forwarding interrupts, and calling the world switch primitive. As far as the host OS was concerned, the device driver was a standard loadable kernel module. But instead of driving some hardware device, it drove the VMM and hid it entirely from the host OS.
When a device raised an interrupt, the CPU could be either running in the host context or the VMM context. In the first case, the CPU transfer control to the host OS via its `Interrupt Descriptor Table (IDT)`. In the second case where an interrupt occur in any VMM context, the steps labeled through (i)-(v) are involved:
* i  : The VMM is interrupted by the CPU and trigger the execution of VMM's external interrupt handler.
* ii : The interrupt handler immediately trigger a world switch back the host OS context, the `idtr` is restored to point to host OS interrupt table.
* iii: The kernel-resident driver transitioned control to the interrupt handler specified by the host OS.
* iv : This is implemented simply by issuing an int `<vector>` instruction with `</vector>`  corresponding to the original external interrupt. The host operating system’s interrupt handler then ran normally, as if the external I/O interrupt had occurred while the VMM driver were processing an `ioctl` in the VMX process.
* v  : The VMM driver then returned control back to the VMX process at userlevel, thereby providing the host OS with the opportunity to make preemptive scheduling decisions.
A part from handling physical interrupts, the illustration shows how VMWare issues I/O requests on behalf of the VMs, All such virtual I/O requests are performed using RPC calls between the VMM and the VMX process which then end up doing a normal syscall to the host OS. To allow overlapped execution of the virtual machine with its own pending I/O requests, the VMX process runs different threads:
* The `Emulator` thread which handle the main loop that execute VM instructions and emulate the device front-ends as part of the processing of RPC calls.
* Other threads `Asychrounous IO (AIO)` are responsible for the execution for all potentially blocking operations.
Now back to the world switch, which is very similar to traditional context switches you might have encountered before (like between the kernel space and user space, or between the debugger and the debuggee), provides the low-level VMM mechanism that loads and executes a VM context, as well as the reverse mechanism that restores the host OS context.
<p align="center"> 
    <img src="https://i.imgur.com/xlEjHkE.png" width="700px" height="auto" alt="Using shadow page tables to virtualize memory">
</p>
The figure above demonstrate how the world switch routine transitionned from the host to the VMM context and vise versa. The VMM is leaving in the top 4MB space. The `cross page` was a single page of memory, used in a very specific manner that is central to the world switch. The cross page was allocated by the kernel-resident driver into the host OS’s kernel address space. Since the driver used standard APIs for the allocation, the host OS determined the address of the cross page.
Immediately before and after each world switch, the cross page was also mapped in the VMM address space. The cross page contained both the code and the data structures for the world switch. Following a disassembly of the instructions that was executed in both directions:
<p align="center"> 
    <img src="https://i.imgur.com/u5Ca2rf.png" width="700px" height="auto" alt="World Switch in VMWare Workstation v1">
</p>
The `VMX` process represent the virtual machine on the host. Its role is to allocate, lock and eventually release all memory ressources. Also, it manages the VM physical memory as a file mapped into its address space (using `mmap` for linux or `file mapping` apis on Windows). Emulation of [DMA](https://en.wikipedia.org/wiki/Direct_memory_access) by a virtual device is a simple `bcopy`, `read` or `write` by the VMX into the right portion of that mapped file. The VMX is working together with the kernel resident driver to provide `Machine Physical Address (mPA)` for the `Guest Physical Address (gPA)` of locked pages. Show a screen shoot of page locking on Windows.
## The Virtual Machine Monitor
Now that we have an idea on the overall hosted architecture of VMWare, let's move to the VMM itself and how it operates. We have seen before that the main function of the VMM is to virtualize the CPU and memory. We discussed also that virtual machines were typically run using an approach known as `trap-and-emulate`. In a
trap-and-emulate style VMM, the guest code runs directly on the CPU, but with `reduced privilege`. When the guest attempts to read or modify privileged state, the processor generates a trap that transfers control to the VMM. The VMM then emulates the instruction using an interpreter and resumes direct execution of the guest at the next instruction. We have said that x86 cannot use trap-and-emulate because of many obstacles as `sensitive non-privileged instructions`. So how to proceed ?
One way would be to run a full system emulation using dynamic binary translation as [Qemu](https://www.qemu.org/) for example do. However, this would generate a significant performance overhead. You could try to download qemu from [here](https://qemu.weilnetz.de/w64/) if you are running Windows and try it by yourself. In linux, you can check this [link](https://www.qemu.org/download/), of course, you should not run it with [KVM](https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine) as Qemu have a mode to accelerate virtualization with KVM, we will talk about it in later chapters.
VMWare comes with a solution which consists of combining `Binary Translation (BT)` and `Direct Execution (DE)`. DE means you can execute execute the assembly instructions as they are, directly on the CPU. BT converts an input executable instruction sequence into a second binary instruction sequence that can execute natively on the target system. A `dynamic` binary translator performs the translation at run-time by storing the target sequences into a buffer called the `translation cache`. VMWare uses DE to run guest user mode applications and BT to run guest system code (kernel). Combining BT and DE limits translator overheads to the time the guest spends running kernel code, which is typically a minority of total execution time. Doing so leads to substantial performance improvements over systems that rely exclusively on binary translation since it allows the direct use of all the hardware components. 
## Protecting the VMM
A VMM must reserve for itself some portion of the guest’s `virtual-address (VA)` space. The VMM could run entirely within the guest’s VA space, which allows it easy access to guest data, although the VMM’s instructions and data structures might use a substantial amount of the guest’s VA space. Alternatively, the VMM could run in a separate address space, but even in that case the VMM must use a minimal amount of the guest’s VA space for the control structures that manage transitions between guest software and the VMM (for example the IDT and the GDT). Anyhow, the VMM must prevent guest access to those portions of the guest’s VA space that the VMM is using. Otherwise, the VMM’s integrity could be compromised if the guest can write to those portions, or the guest could read them (memory leaks).
VMWare VMM share the same address space with the VM and...